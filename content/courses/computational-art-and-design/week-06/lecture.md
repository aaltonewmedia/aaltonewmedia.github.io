---
title: "MON | Lecture"
bookCollapseSection: false
weight: 10
p5js-widget: true
---

# Week 06 | Lecture & Deliverables

---

## Timeline (WIP)

### 2009

[ImageNet](https://en.wikipedia.org/wiki/ImageNet)

## 2012

[AlexNet](https://en.wikipedia.org/wiki/AlexNet)

### 2015

[Google Deep Dream](https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html)

{{<vimeo 132462576>}}

## 2018

[StyleGAN](https://en.wikipedia.org/wiki/StyleGAN)

## 2019

[This Person Does not Exist](https://thispersondoesnotexist.com/)

## 2020

[StyleGAN2](https://en.wikipedia.org/wiki/StyleGAN)
[GPT-3](https://en.wikipedia.org/wiki/GPT-3)

### 2021

January: [DALL-E](https://openai.com/blog/dall-e/)

January: [CLIP](https://openai.com/blog/clip/)

<blockquote class="twitter-tweet" data-theme="dark"><p lang="en" dir="ltr"><a href="https://t.co/DS7XXYMZR8">https://t.co/DS7XXYMZR8</a><br><br>I&#39;m excited to finally share the Colab notebook for generating images from text using the SIREN and CLIP architecture and models.<br><br>Have fun, and please share what you create!</p>&mdash; Adverb (@advadnoun) <a href="https://twitter.com/advadnoun/status/1348375026697834496?ref_src=twsrc%5Etfw">January 10, 2021</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> 

## 2022

April: [DALL-E2]https://openai.com/dall-e-2/

## Different models

### Dall-E 2

- [Website](https://openai.com/dall-e-2/)

### Midjourney

How to use?

1. Join their Discord: [https://discord.gg/midjourney](https://discord.gg/midjourney)
2. Read the instrucions: [https://midjourney.gitbook.io/docs/](https://midjourney.gitbook.io/docs/)
3. You get a trial version

{{<hint info>}}
**Note:** We also have the Midjourney bot on the Aalto Media Lab Discord server. You can use it in any channel. It will start your free trial when you do the command the first time.
{{</hint>}}

### Disco Diffusion

[Open in Google Colab](https://colab.research.google.com/github/alembics/disco-diffusion/blob/main/Disco_Diffusion.ipynb)

<blockquote class="twitter-tweet" data-theme="dark"><p lang="en" dir="ltr">Testing disco diffusion 5.2 Warp. too good! Thanks to <a href="https://twitter.com/devdef?ref_src=twsrc%5Etfw">@devdef</a>. DD offers so many possibilities! Want to make a short film with this technology. <a href="https://t.co/zVDDVFlwxI">pic.twitter.com/zVDDVFlwxI</a></p>&mdash; Remi (@remi_molettee) <a href="https://twitter.com/remi_molettee/status/1526576720924516356?ref_src=twsrc%5Etfw">May 17, 2022</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> 

### Stable Diffusion

- [Stable Diffusion](https://stability.ai/blog/stable-diffusion-public-release)
- [DreamStudio](https://beta.dreamstudio.ai/)

### Deforum Stable Diffusion
- [Site](https://deforum.github.io/)
- [Google Colab](https://colab.research.google.com/github/deforum/stable-diffusion/blob/main/Deforum_Stable_Diffusion.ipynb)
- [GitHub](https://github.com/deforum/stable-diffusion)
- [Run on Google Colab](https://colab.research.google.com/github/deforum/stable-diffusion/blob/main/Deforum_Stable_Diffusion.ipynb)
- [Run on Replicate](https://replicate.com/deforum/deforum_stable_diffusion)

### Realtime VR Stable Diffusion

<blockquote class="twitter-tweet" data-theme="dark"><p lang="en" dir="ltr">I was awoken in the middle of the night to conceptualize this project. Stable Diffusion in VR + touchdesigner = realtime immersive latent space. Tests continue today! <a href="https://twitter.com/hashtag/aiart?src=hash&amp;ref_src=twsrc%5Etfw">#aiart</a> <a href="https://twitter.com/hashtag/vr?src=hash&amp;ref_src=twsrc%5Etfw">#vr</a> <a href="https://twitter.com/hashtag/stablediffusion?src=hash&amp;ref_src=twsrc%5Etfw">#stablediffusion</a> <a href="https://twitter.com/hashtag/touchdesigner?src=hash&amp;ref_src=twsrc%5Etfw">#touchdesigner</a> <a href="https://twitter.com/hashtag/deforum?src=hash&amp;ref_src=twsrc%5Etfw">#deforum</a> <a href="https://t.co/54dk2HjSw7">pic.twitter.com/54dk2HjSw7</a></p>&mdash; ScottieFox (@ScottieFoxTTV) <a href="https://twitter.com/ScottieFoxTTV/status/1578387866572525570?ref_src=twsrc%5Etfw">October 7, 2022</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> 

<blockquote class="twitter-tweet" data-theme="dark"><p lang="en" dir="ltr">The future is now: Real-time immersive latent space. ðŸ”¥<br>The engine sends clips to be diffused. The new content is imported onto the spherical projection when queued.<br>Tools used:<a href="https://t.co/QItMBwCJcQ">https://t.co/QItMBwCJcQ</a> <a href="https://t.co/w6M9DxEALC">https://t.co/w6M9DxEALC</a><a href="https://twitter.com/hashtag/aiart?src=hash&amp;ref_src=twsrc%5Etfw">#aiart</a> <a href="https://twitter.com/hashtag/vr?src=hash&amp;ref_src=twsrc%5Etfw">#vr</a> <a href="https://twitter.com/hashtag/stablediffusion?src=hash&amp;ref_src=twsrc%5Etfw">#stablediffusion</a> <a href="https://twitter.com/hashtag/touchdesigner?src=hash&amp;ref_src=twsrc%5Etfw">#touchdesigner</a> <a href="https://twitter.com/hashtag/deforum?src=hash&amp;ref_src=twsrc%5Etfw">#deforum</a> <a href="https://t.co/PylCcDxVKT">pic.twitter.com/PylCcDxVKT</a></p>&mdash; ScottieFox (@ScottieFoxTTV) <a href="https://twitter.com/ScottieFoxTTV/status/1578911729244729346?ref_src=twsrc%5Etfw">October 9, 2022</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> 


---

## More resources

- [Replicate](https://replicate.com/)
- [Hugging Face](https://huggingface.co/)
- [Phygital AI Library](https://library.phygital.plus)
https://github.com/heejkoo/Awesome-Diffusion-Models
- [Calvin has been working on some information sites](../../tutorials/ai-generators)

### Courses in Aalto

- [CS-E7770 AI for Media, Art and Design](https://sisu.aalto.fi/student/courseunit/aalto-CU-1150933399-20220801/brochure) (this is from the Game Design and Development major)
    - [GitHub of the course](https://github.com/PerttuHamalainen/MediaAI)
    - [Twitter of the course](https://twitter.com/aaltomediaai)